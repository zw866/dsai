# ğŸ“Œ ACTIVITY

## Run Ollama Locally

ğŸ•’ *Estimated Time: 10 minutes*

---

## âœ… Your Task

Install and run Ollama locally on your machine, then test it using the example scripts.

### ğŸ§± Stage 1: Install and Start Ollama

- [ ] Download and install Ollama from [ollama.com](https://ollama.com/download)
- [ ] Start the Ollama server by running `ollama serve` in your terminal (or use [`01_ollama.sh`](01_ollama.sh) to start it in the background)
- [ ] Pull a small model: `ollama pull gemma3:latest` (or use the model specified in the scripts)

### ğŸ§± Stage 2: Test Your Local Ollama

- [ ] Run [`02_ollama.py`](02_ollama.py) or [`02_ollama.R`](02_ollama.R) to query your local Ollama instance
- [ ] Verify you receive a response from the model
- [ ] If you encounter errors, check that the Ollama server is running on port 11434

---

## ğŸ“¤ To Submit

- For credit: Submit a screenshot showing your terminal with Ollama running and the successful output from either the Python or R script.

---

![](../docs/images/icons.png)

---

â† ğŸ  [Back to Top](#ACTIVITY)
